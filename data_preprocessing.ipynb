{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanSmoak/iPrevent/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import common libraries"
      ],
      "metadata": {
        "id": "KTv8-wJsXO8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9Shp_G4YTmX",
        "outputId": "f652c609-33e7-4cef-84a8-4831508f1995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "kj-yV2TlzEck"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold as SKF, cross_val_score as CVS\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import optuna\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define helper functions"
      ],
      "metadata": {
        "id": "2zEsPS8QXTgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load and EDA"
      ],
      "metadata": {
        "id": "jedYFwxGXZWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PefgEk3OzEcl"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "36LwED_bzEcm"
      },
      "outputs": [],
      "source": [
        "def perform_eda(df, dataset_name=\"\"):\n",
        "    \"\"\"Perform exploratory data analysis on the dataset.\"\"\"\n",
        "    # Basic dataset overview\n",
        "    print(f\"{dataset_name} First 5 Rows of Data Set:\\n\", df.head())\n",
        "    print(f\"\\n{dataset_name} Information about the Data Set:\\n\", df.info())\n",
        "    print(f\"\\n{dataset_name} Missing Values in the Data Set:\\n\", df.isnull().sum())\n",
        "    print(f\"\\n{dataset_name} Basic Statistics:\\n\", df.describe())\n",
        "\n",
        "    # Distribution of categorical variables\n",
        "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for column in categorical_columns:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        sns.countplot(data=df, x=column)\n",
        "        plt.title(f'{dataset_name} Distribution of {column}')\n",
        "        plt.show()\n",
        "\n",
        "    # Distribution of numerical variables\n",
        "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    df[numeric_columns].hist(bins=15, figsize=(20, 15))\n",
        "    plt.suptitle(f'{dataset_name} Distribution of numerical variables')\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation matrix (DoctorInCharge column removed if present)\n",
        "    if 'DoctorInCharge' in df.columns:\n",
        "        df_corr = df.drop(columns=['DoctorInCharge'])\n",
        "    else:\n",
        "        df_corr = df.copy()\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    sns.heatmap(df_corr.corr(), annot=True, cmap='coolwarm')\n",
        "    plt.title(f'{dataset_name} Correlation Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning"
      ],
      "metadata": {
        "id": "PCkBBRlkXd09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OO39ctFdzEcm"
      },
      "outputs": [],
      "source": [
        "def handle_missing_values(df, strategy='mean'):\n",
        "    \"\"\"Handle missing values in numerical columns using the specified strategy (mean, median, most_frequent).\"\"\"\n",
        "    imputer = SimpleImputer(strategy=strategy)\n",
        "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "    # Optionally handle categorical columns (e.g., with 'most_frequent')\n",
        "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "    if not categorical_columns.empty:\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preprocessing"
      ],
      "metadata": {
        "id": "yXpCojr6XgCP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7u-acIInzEcm"
      },
      "outputs": [],
      "source": [
        "def encode_categorical_values(df, drop_first=True):\n",
        "    \"\"\"One-hot encode categorical variables. Can drop the first category to avoid multi-collinearity.\"\"\"\n",
        "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first' if drop_first else None)\n",
        "    encoded_columns = pd.DataFrame(encoder.fit_transform(df[categorical_columns]),\n",
        "                                   columns=encoder.get_feature_names_out(categorical_columns),\n",
        "                                   index=df.index)  # Ensure matching index\n",
        "\n",
        "    # Drop original categorical columns and concatenate the encoded columns\n",
        "    df = df.drop(categorical_columns, axis=1)\n",
        "    df = df.drop('PatientID', axis=1)\n",
        "    df = pd.concat([df, encoded_columns], axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Creating new features\n",
        "def create_new_features(df):\n",
        "    # For example, we can add the product of age and BMI as a new feature\n",
        "    df['Age_BMI'] = df['Age'] * df['BMI']\n",
        "    return df\n",
        "\n",
        "\n",
        "# Creating Polynomial Features\n",
        "def add_polynomial_features(df, degree=2):\n",
        "    poly = PolynomialFeatures(degree, include_bias=False)\n",
        "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    poly_features = poly.fit_transform(df[numeric_columns])\n",
        "    poly_feature_names = poly.get_feature_names_out(numeric_columns)\n",
        "    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    poly_df = poly_df.reset_index(drop=True)\n",
        "\n",
        "    df = pd.concat([df, poly_df], axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "26UczCqAjSNG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MX5gY33JzEcn"
      },
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    \"\"\"Normalize numerical columns using StandardScaler (zero mean, unit variance).\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(df):\n",
        "  scaler = StandardScaler()\n",
        "  df_scaled = scaler.fit_transform(df)\n",
        "  df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
        "  return df_scaled"
      ],
      "metadata": {
        "id": "a51SFcprgSQ3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Worker functions"
      ],
      "metadata": {
        "id": "KTFPjtj2XpE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZUSuJC2OzEcn"
      },
      "outputs": [],
      "source": [
        "def save_datasets(X_train, X_test, y_train, y_test, X_cv, y_cv, output_dir):\n",
        "    \"\"\"Save training and testing sets to CSV files.\"\"\"\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save training and testing sets to CSV files\n",
        "    X_train.to_csv(os.path.join(output_dir, 'X_train.csv'), index=False)\n",
        "    X_test.to_csv(os.path.join(output_dir, 'X_test.csv'), index=False)\n",
        "    y_train.to_csv(os.path.join(output_dir, 'y_train.csv'), index=False)\n",
        "    y_test.to_csv(os.path.join(output_dir, 'y_test.csv'), index=False)\n",
        "    X_cv.to_csv(os.path.join(output_dir, 'X_cv.csv'), index=False)\n",
        "    y_cv.to_csv(os.path.join(output_dir, 'y_cv.csv'), index=False)\n",
        "\n",
        "    # Print confirmation message\n",
        "    print(f\"Datasets saved to {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "UNA-zuZfzEcn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def main(data, target_column, output_dir):\n",
        "    \"\"\"Main function to run the data processing pipeline.\"\"\"\n",
        "    df = data.drop(columns=['Diagnosis'])\n",
        "    df_target = data['Diagnosis']\n",
        "\n",
        "    #perform_eda(df, dataset_name=\"Original\")\n",
        "    df = handle_missing_values(df)\n",
        "    df = encode_categorical_values(df)\n",
        "    #df = normalize_data(df)\n",
        "    df = scale(df)\n",
        "    if 'PatientID' in df.columns:\n",
        "      df = df.drop(columns=['PatientID'])\n",
        "    else:\n",
        "      print(\"Column 'PatientID' not found in DataFrame. Skipping drop operation.\")\n",
        "\n",
        "\n",
        "    # Splitting data into training and testing sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(df, df_target, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Splitting the temporary set into cross-validation and testing sets\n",
        "    X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    save_datasets(X_train, X_test, y_train, y_test, X_cv, y_cv, output_dir)\n",
        "\n",
        "    # Convert the target variable to categorical if it's not already\n",
        "    # Assuming 'Diagnosis' should be treated as a categorical variable\n",
        "    y_train = y_train.astype('category')\n",
        "    y_test = y_test.astype('category')\n",
        "    y_cv = y_cv.astype('category')\n",
        "\n",
        "    # Oversample the training, test and cv set\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "    X_test, y_test = smote.fit_resample(X_test, y_test)\n",
        "    X_cv, y_cv = smote.fit_resample(X_cv, y_cv)\n",
        "\n",
        "\n",
        "    # Column analysis for training, cross-validation, and test sets\n",
        "    #perform_eda(pd.concat([X_train, y_train], axis=1), dataset_name=\"Training Set\")\n",
        "    #perform_eda(pd.concat([X_test, y_test], axis=1), dataset_name=\"Test Set\")\n",
        "    #perform_eda(pd.concat([X_cv, y_cv], axis=1), dataset_name=\"Cross Validation Set\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, X_cv, y_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Drive"
      ],
      "metadata": {
        "id": "TfnldRQ7Xs48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to drive and get data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/KamiLimu/iPrevent/diabetes_data.csv',\n",
        "                   index_col= None,\n",
        "                   header = 0,)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "nTRuq1rnzmP3",
        "outputId": "ea53ce8e-16ca-43ac-f722-fb9fa9249732"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PatientID  Age  Gender  SocioeconomicStatus        BMI  Smoking  \\\n",
              "0       6000   44       0                    2  32.985284        1   \n",
              "1       6001   51       1                    1  39.916764        0   \n",
              "2       6002   89       1                    1  19.782251        0   \n",
              "3       6003   21       1                    1  32.376881        1   \n",
              "4       6004   27       1                    1  16.808600        0   \n",
              "\n",
              "   AlcoholConsumption  PhysicalActivity  DietQuality  SleepQuality  ...  \\\n",
              "0            4.499365          2.443385     4.898831      4.049885  ...   \n",
              "1            1.578919          8.301264     8.941093      7.508150  ...   \n",
              "2            1.177301          6.103395     7.722543      7.708387  ...   \n",
              "3            1.714621          8.645465     4.804044      6.286548  ...   \n",
              "4           15.462549          4.629383     2.532756      9.771125  ...   \n",
              "\n",
              "   AntihypertensiveMedications  AntidiabeticMedications  FrequentUrination  \\\n",
              "0                            0                        1                  0   \n",
              "1                            0                        0                  0   \n",
              "2                            1                        0                  0   \n",
              "3                            0                        1                  0   \n",
              "4                            1                        0                  0   \n",
              "\n",
              "   ExcessiveThirst  UnexplainedWeightLoss  FatigueLevels  BlurredVision  \\\n",
              "0                0                      0       9.534169              0   \n",
              "1                0                      0       0.123214              0   \n",
              "2                0                      0       9.643320              0   \n",
              "3                0                      0       3.403557              0   \n",
              "4                0                      0       2.924687              0   \n",
              "\n",
              "   SlowHealingSores  TinglingHandsFeet  Diagnosis  \n",
              "0                 0                  1          1  \n",
              "1                 0                  0          1  \n",
              "2                 0                  0          0  \n",
              "3                 0                  0          0  \n",
              "4                 0                  0          0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19352ef6-93fe-4f1b-ba90-b1940b5c09a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>SocioeconomicStatus</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>AlcoholConsumption</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>DietQuality</th>\n",
              "      <th>SleepQuality</th>\n",
              "      <th>...</th>\n",
              "      <th>AntihypertensiveMedications</th>\n",
              "      <th>AntidiabeticMedications</th>\n",
              "      <th>FrequentUrination</th>\n",
              "      <th>ExcessiveThirst</th>\n",
              "      <th>UnexplainedWeightLoss</th>\n",
              "      <th>FatigueLevels</th>\n",
              "      <th>BlurredVision</th>\n",
              "      <th>SlowHealingSores</th>\n",
              "      <th>TinglingHandsFeet</th>\n",
              "      <th>Diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6000</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>32.985284</td>\n",
              "      <td>1</td>\n",
              "      <td>4.499365</td>\n",
              "      <td>2.443385</td>\n",
              "      <td>4.898831</td>\n",
              "      <td>4.049885</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.534169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6001</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39.916764</td>\n",
              "      <td>0</td>\n",
              "      <td>1.578919</td>\n",
              "      <td>8.301264</td>\n",
              "      <td>8.941093</td>\n",
              "      <td>7.508150</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.123214</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6002</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.782251</td>\n",
              "      <td>0</td>\n",
              "      <td>1.177301</td>\n",
              "      <td>6.103395</td>\n",
              "      <td>7.722543</td>\n",
              "      <td>7.708387</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.643320</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6003</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>32.376881</td>\n",
              "      <td>1</td>\n",
              "      <td>1.714621</td>\n",
              "      <td>8.645465</td>\n",
              "      <td>4.804044</td>\n",
              "      <td>6.286548</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.403557</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6004</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.808600</td>\n",
              "      <td>0</td>\n",
              "      <td>15.462549</td>\n",
              "      <td>4.629383</td>\n",
              "      <td>2.532756</td>\n",
              "      <td>9.771125</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.924687</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19352ef6-93fe-4f1b-ba90-b1940b5c09a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19352ef6-93fe-4f1b-ba90-b1940b5c09a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19352ef6-93fe-4f1b-ba90-b1940b5c09a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e727ce0-d564-4470-85b4-96d12ae434dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e727ce0-d564-4470-85b4-96d12ae434dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e727ce0-d564-4470-85b4-96d12ae434dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.drop([\"Diagnosis\"],axis=1)\n",
        "y=data[\"Diagnosis\"]\n",
        "\n",
        "count_class = y.value_counts() # Count the occurrences of each class\n",
        "plt.bar(count_class.index, count_class.values)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Class Distribution')\n",
        "plt.xticks(range(len(count_class.index)), count_class.index)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tS6goI-E9c_9",
        "outputId": "8372c006-a0ed-4852-fb33-f9b1796eea5f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find unique values in a column\n",
        "data[\"Diagnosis\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQcLzTCeC134",
        "outputId": "708f7f13-f2a3-4188-836e-17b94bf39420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The actual Main"
      ],
      "metadata": {
        "id": "6lsg2D3laFri"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z08KC2BmzEco",
        "outputId": "09b260d1-a8cf-44de-d1aa-a6572a76bdf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'PatientID' not found in DataFrame. Skipping drop operation.\n",
            "Datasets saved to /content/drive/MyDrive/KamiLimu/iPrevent\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    target_column = \"Diagnosis\"  # Target variable\n",
        "    output_dir = r\"/content/drive/MyDrive/KamiLimu/iPrevent\"  # Directory to save\n",
        "    X_train, X_test, y_train, y_test, X_cv, y_cv = main(data, target_column, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Modeling"
      ],
      "metadata": {
        "id": "4tSE5y4HKxT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Random Forest"
      ],
      "metadata": {
        "id": "NbeeisuzX6yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries needed for the model\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "oMis6aUXKzz7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of the classifier with default parameters\n",
        "clf = RandomForestClassifier(random_state=42,\n",
        "                             bootstrap= False,\n",
        "                             max_depth=30,\n",
        "                             max_features = 'sqrt',\n",
        "                             min_samples_leaf= 1, min_samples_split = 2,\n",
        "                             n_estimators= 200)\n",
        "\n",
        "skf = SKF(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "#fit the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame\n",
        "importances_df = pd.DataFrame({'feature': X_train.columns, 'importance': feature_importances})\n",
        "\n",
        "# Sort by importance\n",
        "importances_df = importances_df.sort_values(by='importance', ascending=False)\n",
        "importances_df.head(10)\n",
        "\n",
        "print(importances_df)\n",
        "\n",
        "#make predictions on the test set\n",
        "y_pred = clf.predict(X_cv)\n",
        "\n",
        "#calculate accuracy, precision_recall, f1_score\n",
        "scores = CVS(clf, X_train, y_train, cv=skf)\n",
        "print(f\"Cross-Validation Accuracy: {scores.mean()}\")\n",
        "print(f\"Mean CV Accuracy: {scores.mean():.2f}\")\n",
        "accuracy = accuracy_score(y_cv, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "precision = precision_score(y_cv, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "recall = recall_score(y_cv, y_pred, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "f1 = f1_score(y_cv, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABn7X6KQLVAi",
        "outputId": "9d2a33a5-2d7d-4660-af7f-77d98b5aa19d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        feature  importance\n",
            "7                   DietQuality    0.094534\n",
            "22                      Age_BMI    0.094395\n",
            "8                  SleepQuality    0.092410\n",
            "6              PhysicalActivity    0.091132\n",
            "18                FatigueLevels    0.090856\n",
            "3                           BMI    0.090121\n",
            "5            AlcoholConsumption    0.089768\n",
            "0                           Age    0.081185\n",
            "2           SocioeconomicStatus    0.043627\n",
            "15            FrequentUrination    0.027491\n",
            "12                 Hypertension    0.023612\n",
            "1                        Gender    0.021654\n",
            "4                       Smoking    0.021199\n",
            "9         FamilyHistoryDiabetes    0.018079\n",
            "16              ExcessiveThirst    0.017753\n",
            "13  AntihypertensiveMedications    0.017711\n",
            "14      AntidiabeticMedications    0.017160\n",
            "11          PreviousPreDiabetes    0.013895\n",
            "21            TinglingHandsFeet    0.011756\n",
            "17        UnexplainedWeightLoss    0.011591\n",
            "19                BlurredVision    0.010494\n",
            "10          GestationalDiabetes    0.010066\n",
            "20             SlowHealingSores    0.009510\n",
            "Cross-Validation Accuracy: 0.6890239894840617\n",
            "Mean CV Accuracy: 0.69\n",
            "Accuracy: 0.7024793388429752\n",
            "Precision: 0.7081665613369847\n",
            "Recall: 0.7024793388429752\n",
            "F1 Score: 0.7004332576851661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ed-ImRTlbKCO",
        "outputId": "7a788078-9856-40cb-c791-a232a1e4e504"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                feature  importance\n",
              "7           DietQuality    0.094534\n",
              "22              Age_BMI    0.094395\n",
              "8          SleepQuality    0.092410\n",
              "6      PhysicalActivity    0.091132\n",
              "18        FatigueLevels    0.090856\n",
              "3                   BMI    0.090121\n",
              "5    AlcoholConsumption    0.089768\n",
              "0                   Age    0.081185\n",
              "2   SocioeconomicStatus    0.043627\n",
              "15    FrequentUrination    0.027491"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0aaaf834-04f4-4b94-ac80-75f2a68b0239\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DietQuality</td>\n",
              "      <td>0.094534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Age_BMI</td>\n",
              "      <td>0.094395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SleepQuality</td>\n",
              "      <td>0.092410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PhysicalActivity</td>\n",
              "      <td>0.091132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>FatigueLevels</td>\n",
              "      <td>0.090856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMI</td>\n",
              "      <td>0.090121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AlcoholConsumption</td>\n",
              "      <td>0.089768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Age</td>\n",
              "      <td>0.081185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SocioeconomicStatus</td>\n",
              "      <td>0.043627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>FrequentUrination</td>\n",
              "      <td>0.027491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aaaf834-04f4-4b94-ac80-75f2a68b0239')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0aaaf834-04f4-4b94-ac80-75f2a68b0239 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0aaaf834-04f4-4b94-ac80-75f2a68b0239');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4936e2a1-5cba-45fb-81b8-5e5af04b170c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4936e2a1-5cba-45fb-81b8-5e5af04b170c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4936e2a1-5cba-45fb-81b8-5e5af04b170c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "importances_df",
              "summary": "{\n  \"name\": \"importances_df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"AntihypertensiveMedications\",\n          \"FrequentUrination\",\n          \"DietQuality\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03592423645827585,\n        \"min\": 0.009510307683426563,\n        \"max\": 0.0945338940126755,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.017711022825228826,\n          0.027491321462127124,\n          0.0945338940126755\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import gridsearchcv\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#create parameter grid for searching\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "#create an object of gridsearchcv\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "#fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters include: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_rA46XqaL5MA",
        "outputId": "b1a223fa-1412-4efc-e6d8-791224d25f8f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e4ea5a72af29>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters include: {grid_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import randomizedsearchcv\n",
        "from sklearn.model_selection import RandomizedSearchCV as RCV\n",
        "import numpy as np\n",
        "\n",
        "#create parameter dist for searching\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.05, 0.2, 0.3, 0.5],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20, 30, 40],\n",
        "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 12, 14],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'criterion': ['friedman_mse', 'mse', 'mae'],\n",
        "    'loss': ['deviance', 'exponential'],\n",
        "    'min_impurity_decrease': [0.0, 0.01, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "#create an object of rcv\n",
        "random_search = RCV(estimator=gbm,\n",
        "                    param_distributions=param_dist,\n",
        "                    n_iter = 100, cv=5,\n",
        "                    random_state= 42, n_jobs=-1)\n",
        "\n",
        "#fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters include: {random_search.best_params_}\")\n",
        "print(f\"Best score: {random_search.best_score_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHqNPfYnrs8u",
        "outputId": "c6613c98-b5de-47ac-ec3a-c436886370a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "415 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "115 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mae' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "93 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mse' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "47 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mse' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "95 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.63711876\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.62762781        nan        nan        nan\n",
            "        nan        nan        nan 0.64158803        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.64326244\n",
            "        nan        nan        nan        nan 0.65334022 0.64606826\n",
            " 0.6449306         nan        nan        nan 0.63038668 0.66339921\n",
            "        nan        nan 0.63601709 0.65388792        nan 0.62928188\n",
            "        nan        nan        nan 0.62872166 0.63432233        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.64212791 0.66395787        nan        nan\n",
            "        nan        nan        nan 0.64659093]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters include: {'subsample': 0.7, 'n_estimators': 900, 'min_samples_split': 15, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'loss': 'exponential', 'learning_rate': 0.01, 'criterion': 'friedman_mse'}\n",
            "Best score: 0.6639578736522541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(params):\n",
        "    n_estimators = int(params['n_estimators'])\n",
        "    max_depth = int(params['max_depth'])\n",
        "    min_samples_split = int(params['min_samples_split'])\n",
        "    min_samples_leaf = int(params['min_samples_leaf'])\n",
        "    bootstrap = params['bootstrap']\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, random_state=42)\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "    return {'loss': 1 - scores.mean(), 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "fX1asQLSbbGp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 100, 200, 50),\n",
        "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
        "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
        "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1),\n",
        "    'bootstrap': hp.choice('bootstrap', [True, False])\n",
        "}"
      ],
      "metadata": {
        "id": "2M7vKRH3bepR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n",
        "print(\"Best parameters found: \", best)\n",
        "print(\"Best cross-validation score: \", 1 - trials.best_trial['result']['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTCcfQLTbgrh",
        "outputId": "7550a60f-38ea-4cff-e3c6-78f9aa180c11"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 100/100 [05:43<00:00,  3.44s/trial, best loss: 0.3198253603117225]\n",
            "Best parameters found:  {'bootstrap': 1, 'max_depth': 10.0, 'min_samples_leaf': 1.0, 'min_samples_split': 6.0, 'n_estimators': 200.0}\n",
            "Best cross-validation score:  0.6801746396882775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### XGBoost"
      ],
      "metadata": {
        "id": "p6hpnk9AX_rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries for XGBoost and stacking\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "PkpnE1DPwR7X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of the xgboost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',random_state=42)\n",
        "\n",
        "#fit the model\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "#make prediction on the test set\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "#calculate accuracy, precision_recall, f1_score\n",
        "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQu_aUBZw1gs",
        "outputId": "4bde17ab-eae8-434a-f509-802300b2ee89"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:13:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import randomizedsearchcv\n",
        "from sklearn.model_selection import RandomizedSearchCV as RCV\n",
        "import numpy as np\n",
        "\n",
        "#create parameter dist for searching\n",
        "param_grid = {\n",
        "    'n_estimators': np.arange(50, 200, 50),\n",
        "    'max_depth': np.arange(3, 10, 1),\n",
        "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
        "    'subsample': np.linspace(0.5, 1.0, 10),\n",
        "    'colsample_bytree': np.linspace(0.5, 1.0, 10),\n",
        "    'min_child_weight': np.arange(1, 10, 1),\n",
        "    'gamma': np.linspace(0, 0.5, 10)\n",
        "}\n",
        "\n",
        "#create an object of rcv\n",
        "random_search = RCV(estimator=xgb,\n",
        "                    param_distributions=param_grid,\n",
        "                    n_iter = 100, cv=5,\n",
        "                    random_state= 42, n_jobs=-1)\n",
        "\n",
        "#fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters include: {random_search.best_params_}\")\n",
        "print(f\"Best score: {random_search.best_score_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Sqc4_sxqKa",
        "outputId": "8c8b8a01-5df3-4ff8-c691-3a9d987ecc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:11:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters include: {'subsample': 0.9444444444444444, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.1711111111111111, 'gamma': 0.16666666666666666, 'colsample_bytree': 0.5555555555555556}\n",
            "Best score: 0.6527518269877783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def obj_fun(trial):\n",
        "    # Suggest hyperparameters\n",
        "    n_estimators = trial.suggest_int('n_estimators',\n",
        "                                     100, 200)\n",
        "    max_depth = trial.suggest_int('max_depth',\n",
        "                                  3, 10)\n",
        "    learning_rate = trial.suggest_float('learning_rate',\n",
        "                                        0.01, 0.3)\n",
        "    subsample = trial.suggest_float('subsample',\n",
        "                                    0.5, 1.0)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree',\n",
        "                                           0.5, 1.0)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight',\n",
        "                                         1, 10)\n",
        "    gamma = trial.suggest_float('gamma',\n",
        "                                0, 0.5)\n",
        "\n",
        "    # Train the model\n",
        "    model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, subsample=subsample, colsample_bytree=colsample_bytree, min_child_weight=min_child_weight, gamma=gamma, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    return -accuracy  # Negative accuracy to minimize"
      ],
      "metadata": {
        "id": "BKgmLmOZXPfq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(obj_fun, n_trials=100, n_jobs=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWhVv0P5YahM",
        "outputId": "473e5492-74c1-4871-b791-704d6be75389"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-16 08:12:18,049] A new study created in memory with name: no-name-75061c52-6a13-4b24-8204-bbb35fb8f54a\n",
            "[I 2024-10-16 08:12:18,853] Trial 0 finished with value: -0.5848214285714286 and parameters: {'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.06285396909819387, 'subsample': 0.813553299940555, 'colsample_bytree': 0.6227203288299967, 'min_child_weight': 6, 'gamma': 0.3299214536285558}. Best is trial 0 with value: -0.5848214285714286.\n",
            "[I 2024-10-16 08:12:18,883] Trial 1 finished with value: -0.6116071428571429 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.03713358194677073, 'subsample': 0.5953812614741965, 'colsample_bytree': 0.9117789295236964, 'min_child_weight': 10, 'gamma': 0.39235804830263604}. Best is trial 1 with value: -0.6116071428571429.\n",
            "[I 2024-10-16 08:12:19,597] Trial 2 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 198, 'max_depth': 6, 'learning_rate': 0.29641838523079617, 'subsample': 0.864712632073442, 'colsample_bytree': 0.7834603808478782, 'min_child_weight': 5, 'gamma': 0.4165575821681747}. Best is trial 1 with value: -0.6116071428571429.\n",
            "[I 2024-10-16 08:12:19,625] Trial 3 finished with value: -0.5580357142857143 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.12512170839105222, 'subsample': 0.567643142524614, 'colsample_bytree': 0.9284284676882577, 'min_child_weight': 5, 'gamma': 0.35997330320932475}. Best is trial 1 with value: -0.6116071428571429.\n",
            "[I 2024-10-16 08:12:20,083] Trial 4 finished with value: -0.59375 and parameters: {'n_estimators': 139, 'max_depth': 4, 'learning_rate': 0.19476642375559547, 'subsample': 0.9918129781449059, 'colsample_bytree': 0.5017559930206604, 'min_child_weight': 2, 'gamma': 0.15774086367703088}. Best is trial 1 with value: -0.6116071428571429.\n",
            "[I 2024-10-16 08:12:20,164] Trial 5 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.21925574201951, 'subsample': 0.7752532881794976, 'colsample_bytree': 0.7847484630509916, 'min_child_weight': 9, 'gamma': 0.11087717463693886}. Best is trial 1 with value: -0.6116071428571429.\n",
            "[I 2024-10-16 08:12:20,700] Trial 6 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 102, 'max_depth': 9, 'learning_rate': 0.26944111639810414, 'subsample': 0.9530413774404148, 'colsample_bytree': 0.7986407166949481, 'min_child_weight': 10, 'gamma': 0.3348050937284424}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:21,132] Trial 7 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 195, 'max_depth': 9, 'learning_rate': 0.2244347074212062, 'subsample': 0.9384622395693345, 'colsample_bytree': 0.7679675054883404, 'min_child_weight': 6, 'gamma': 0.02708968081594082}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:21,814] Trial 8 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.08380696996369283, 'subsample': 0.9709822343945709, 'colsample_bytree': 0.9618700172046223, 'min_child_weight': 6, 'gamma': 0.0742052766155899}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:22,236] Trial 10 finished with value: -0.5848214285714286 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.12726250704152567, 'subsample': 0.7718594969922843, 'colsample_bytree': 0.8540491269172558, 'min_child_weight': 7, 'gamma': 0.0246230646721049}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:22,305] Trial 9 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 186, 'max_depth': 9, 'learning_rate': 0.2507239317393951, 'subsample': 0.6355807725666307, 'colsample_bytree': 0.9417643693122348, 'min_child_weight': 6, 'gamma': 0.25396423171157295}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:23,197] Trial 11 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.2980775937337609, 'subsample': 0.6657984064617288, 'colsample_bytree': 0.6686434143864568, 'min_child_weight': 1, 'gamma': 0.237114904468323}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:23,233] Trial 12 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.04928631576411205, 'subsample': 0.6662620490664596, 'colsample_bytree': 0.6810237393781811, 'min_child_weight': 10, 'gamma': 0.4524533983803292}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:24,167] Trial 13 finished with value: -0.5491071428571429 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.2989777848165359, 'subsample': 0.6832724627582984, 'colsample_bytree': 0.6431634509339239, 'min_child_weight': 1, 'gamma': 0.4949776311888384}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:24,427] Trial 14 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 174, 'max_depth': 7, 'learning_rate': 0.2992057077018197, 'subsample': 0.7018563635835676, 'colsample_bytree': 0.6602724172788209, 'min_child_weight': 1, 'gamma': 0.25079130221564744}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:24,998] Trial 15 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.26127454849003473, 'subsample': 0.5164992005016709, 'colsample_bytree': 0.7043768786051133, 'min_child_weight': 3, 'gamma': 0.2649059685072031}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:25,121] Trial 16 finished with value: -0.5580357142857143 and parameters: {'n_estimators': 133, 'max_depth': 8, 'learning_rate': 0.2544686600400813, 'subsample': 0.5002080611228519, 'colsample_bytree': 0.5466404248831263, 'min_child_weight': 3, 'gamma': 0.17154114657657893}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:25,416] Trial 17 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.17203521740405373, 'subsample': 0.8544678980725015, 'colsample_bytree': 0.5679447727464214, 'min_child_weight': 3, 'gamma': 0.20271487328347998}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:25,655] Trial 18 finished with value: -0.6116071428571429 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.18649853684232992, 'subsample': 0.8873262043677285, 'colsample_bytree': 0.8496405044556941, 'min_child_weight': 8, 'gamma': 0.3108494906895861}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:25,843] Trial 19 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 181, 'max_depth': 3, 'learning_rate': 0.21840450120887667, 'subsample': 0.7222280719337526, 'colsample_bytree': 0.8443722446642349, 'min_child_weight': 8, 'gamma': 0.3148423710445041}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:26,378] Trial 20 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.27070577107112676, 'subsample': 0.7266260402820289, 'colsample_bytree': 0.7262391089452515, 'min_child_weight': 4, 'gamma': 0.3001714928735178}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:26,445] Trial 21 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 145, 'max_depth': 10, 'learning_rate': 0.27375548472230743, 'subsample': 0.9063398812636346, 'colsample_bytree': 0.7310864749128163, 'min_child_weight': 4, 'gamma': 0.20177005994021704}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:27,366] Trial 22 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.01325713950831528, 'subsample': 0.6080194114957118, 'colsample_bytree': 0.8880918581985093, 'min_child_weight': 10, 'gamma': 0.38962385550727174}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:27,433] Trial 23 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 161, 'max_depth': 9, 'learning_rate': 0.019618081303084962, 'subsample': 0.6070802373938169, 'colsample_bytree': 0.8989050599806275, 'min_child_weight': 10, 'gamma': 0.38513088314224764}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:28,535] Trial 25 finished with value: -0.5714285714285714 and parameters: {'n_estimators': 162, 'max_depth': 8, 'learning_rate': 0.13913154041452713, 'subsample': 0.6465322336758925, 'colsample_bytree': 0.8098327134167043, 'min_child_weight': 9, 'gamma': 0.4334018380240378}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:28,713] Trial 24 finished with value: -0.625 and parameters: {'n_estimators': 162, 'max_depth': 9, 'learning_rate': 0.020402253254653377, 'subsample': 0.6255918910568261, 'colsample_bytree': 0.8905253887665053, 'min_child_weight': 9, 'gamma': 0.3775677260312412}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:29,921] Trial 27 finished with value: -0.6116071428571429 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.10063818286162379, 'subsample': 0.8195254474183139, 'colsample_bytree': 0.6098160604363496, 'min_child_weight': 8, 'gamma': 0.3541911074585614}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:30,001] Trial 26 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 177, 'max_depth': 9, 'learning_rate': 0.10570518067367424, 'subsample': 0.6010093657580816, 'colsample_bytree': 0.880261249464076, 'min_child_weight': 8, 'gamma': 0.3552045030208001}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:30,804] Trial 29 finished with value: -0.5803571428571429 and parameters: {'n_estimators': 117, 'max_depth': 7, 'learning_rate': 0.2368868795088203, 'subsample': 0.5478171255530553, 'colsample_bytree': 0.8146352942411611, 'min_child_weight': 9, 'gamma': 0.29337323816327154}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:30,969] Trial 28 finished with value: -0.5535714285714286 and parameters: {'n_estimators': 142, 'max_depth': 9, 'learning_rate': 0.22729039610847535, 'subsample': 0.5706113504624026, 'colsample_bytree': 0.8211414276868415, 'min_child_weight': 9, 'gamma': 0.20780635970005026}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:31,872] Trial 30 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 145, 'max_depth': 10, 'learning_rate': 0.15598571474461484, 'subsample': 0.8082554435880753, 'colsample_bytree': 0.989539509892231, 'min_child_weight': 7, 'gamma': 0.4795579769664014}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:31,895] Trial 31 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.0665926311125968, 'subsample': 0.7503259043446098, 'colsample_bytree': 0.607279574146072, 'min_child_weight': 7, 'gamma': 0.47670610616028825}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:32,588] Trial 33 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 152, 'max_depth': 8, 'learning_rate': 0.011321115732710586, 'subsample': 0.6309339040527088, 'colsample_bytree': 0.88673220805556, 'min_child_weight': 10, 'gamma': 0.3930835139068322}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:32,608] Trial 32 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 153, 'max_depth': 8, 'learning_rate': 0.01811325007645123, 'subsample': 0.6392897325122724, 'colsample_bytree': 0.8814575601242689, 'min_child_weight': 10, 'gamma': 0.39166124051372453}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:33,270] Trial 34 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 149, 'max_depth': 8, 'learning_rate': 0.03747075015707389, 'subsample': 0.6343589034772757, 'colsample_bytree': 0.7631114598583598, 'min_child_weight': 10, 'gamma': 0.42371164004198325}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:33,318] Trial 35 finished with value: -0.625 and parameters: {'n_estimators': 151, 'max_depth': 8, 'learning_rate': 0.035543110605465625, 'subsample': 0.6383068120358404, 'colsample_bytree': 0.9277719894569757, 'min_child_weight': 10, 'gamma': 0.4013662388922348}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:33,795] Trial 37 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.06623538780493356, 'subsample': 0.5416268891332157, 'colsample_bytree': 0.8694198604722064, 'min_child_weight': 9, 'gamma': 0.3425724831929227}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:34,014] Trial 36 finished with value: -0.6116071428571429 and parameters: {'n_estimators': 154, 'max_depth': 7, 'learning_rate': 0.06183161886814643, 'subsample': 0.559205033118391, 'colsample_bytree': 0.9310062355262934, 'min_child_weight': 9, 'gamma': 0.3378747534775868}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:34,345] Trial 38 finished with value: -0.6428571428571429 and parameters: {'n_estimators': 116, 'max_depth': 7, 'learning_rate': 0.022748121988059426, 'subsample': 0.5754995578503602, 'colsample_bytree': 0.912472887324799, 'min_child_weight': 9, 'gamma': 0.37636963463942974}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:34,706] Trial 39 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 135, 'max_depth': 9, 'learning_rate': 0.026513081676473038, 'subsample': 0.6797834553865352, 'colsample_bytree': 0.9768308363422964, 'min_child_weight': 10, 'gamma': 0.3800328878743323}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:34,890] Trial 40 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.036570666667379445, 'subsample': 0.699786155475721, 'colsample_bytree': 0.9986634236690382, 'min_child_weight': 10, 'gamma': 0.4487057778505158}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:35,199] Trial 41 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.08781467627611755, 'subsample': 0.5764807704803663, 'colsample_bytree': 0.9553257260159749, 'min_child_weight': 10, 'gamma': 0.450307816623276}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:35,407] Trial 42 finished with value: -0.6428571428571429 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.010121299167583697, 'subsample': 0.587574784551203, 'colsample_bytree': 0.9587570377824328, 'min_child_weight': 10, 'gamma': 0.4461401449657656}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:35,715] Trial 43 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 119, 'max_depth': 6, 'learning_rate': 0.04742532615129687, 'subsample': 0.7067182718205617, 'colsample_bytree': 0.917521887010735, 'min_child_weight': 10, 'gamma': 0.41022501152283486}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:35,923] Trial 44 finished with value: -0.6294642857142857 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.01028230133049374, 'subsample': 0.583163084711499, 'colsample_bytree': 0.9191973895082552, 'min_child_weight': 9, 'gamma': 0.40959826125011606}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:36,096] Trial 45 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.013978298391223345, 'subsample': 0.5315913864354546, 'colsample_bytree': 0.7886520647824994, 'min_child_weight': 9, 'gamma': 0.27816802964721743}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:36,409] Trial 46 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.05338065245411368, 'subsample': 0.537424074017099, 'colsample_bytree': 0.9569121990029117, 'min_child_weight': 8, 'gamma': 0.36404971750211107}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:36,695] Trial 47 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.04799200422347738, 'subsample': 0.9592791197306321, 'colsample_bytree': 0.9527927555944122, 'min_child_weight': 8, 'gamma': 0.3657379488491904}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:36,929] Trial 48 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.031499413680925265, 'subsample': 0.9930056307738635, 'colsample_bytree': 0.8535640292364567, 'min_child_weight': 10, 'gamma': 0.4328588173873965}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:37,261] Trial 49 finished with value: -0.6294642857142857 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.029578992905646716, 'subsample': 0.6640200846257854, 'colsample_bytree': 0.8604930058519616, 'min_child_weight': 10, 'gamma': 0.4395777486495743}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:37,440] Trial 50 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.07842060713617907, 'subsample': 0.658068261731888, 'colsample_bytree': 0.8321911964080606, 'min_child_weight': 10, 'gamma': 0.4722982620579358}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:37,741] Trial 51 finished with value: -0.5982142857142857 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.08222756646387905, 'subsample': 0.6247285005962487, 'colsample_bytree': 0.8301097725682114, 'min_child_weight': 7, 'gamma': 0.32429823999090346}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:37,909] Trial 52 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.0422853325233246, 'subsample': 0.6240064363329293, 'colsample_bytree': 0.9835280632983159, 'min_child_weight': 10, 'gamma': 0.45782009276460595}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:38,225] Trial 53 finished with value: -0.5848214285714286 and parameters: {'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.04098277971855381, 'subsample': 0.589303651415436, 'colsample_bytree': 0.9970787999386554, 'min_child_weight': 9, 'gamma': 0.4640245091728674}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:38,331] Trial 54 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.20266396122481645, 'subsample': 0.6884123669955606, 'colsample_bytree': 0.9084819191504142, 'min_child_weight': 9, 'gamma': 0.49967178675400564}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:38,716] Trial 55 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.026463932492142538, 'subsample': 0.691546674266542, 'colsample_bytree': 0.9062313430946695, 'min_child_weight': 9, 'gamma': 0.4893085158606879}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:38,906] Trial 56 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 122, 'max_depth': 7, 'learning_rate': 0.024838666186143343, 'subsample': 0.7542232220972754, 'colsample_bytree': 0.9724613770226394, 'min_child_weight': 10, 'gamma': 0.41595985669864394}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:39,230] Trial 58 finished with value: -0.5714285714285714 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.2843764628148663, 'subsample': 0.7205689529495057, 'colsample_bytree': 0.9394286247887347, 'min_child_weight': 10, 'gamma': 0.0009735025253527763}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:39,323] Trial 57 finished with value: -0.6071428571428571 and parameters: {'n_estimators': 119, 'max_depth': 7, 'learning_rate': 0.057879247319440795, 'subsample': 0.7912101004310702, 'colsample_bytree': 0.9716569475109835, 'min_child_weight': 10, 'gamma': 0.40272236204038275}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:39,810] Trial 60 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 104, 'max_depth': 8, 'learning_rate': 0.010121799941359698, 'subsample': 0.6083025632527356, 'colsample_bytree': 0.8791848285185995, 'min_child_weight': 9, 'gamma': 0.44151169379192096}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:40,026] Trial 59 finished with value: -0.6026785714285714 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.05527405983011095, 'subsample': 0.9180475857896196, 'colsample_bytree': 0.7970536263705784, 'min_child_weight': 5, 'gamma': 0.3956919638686132}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:40,331] Trial 61 finished with value: -0.5446428571428571 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.12809049914447937, 'subsample': 0.5082436229334625, 'colsample_bytree': 0.7939955250810222, 'min_child_weight': 5, 'gamma': 0.3936485380328534}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:40,505] Trial 62 finished with value: -0.6383928571428571 and parameters: {'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.0249966768430094, 'subsample': 0.6973764331512713, 'colsample_bytree': 0.9002874350169692, 'min_child_weight': 9, 'gamma': 0.4860146628951614}. Best is trial 6 with value: -0.6517857142857143.\n",
            "[I 2024-10-16 08:12:40,802] Trial 63 finished with value: -0.6607142857142857 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.022534083523465802, 'subsample': 0.7051065000985274, 'colsample_bytree': 0.8983693853883284, 'min_child_weight': 9, 'gamma': 0.48798158251804163}. Best is trial 63 with value: -0.6607142857142857.\n",
            "[I 2024-10-16 08:12:40,968] Trial 64 finished with value: -0.6383928571428571 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.01922071837231844, 'subsample': 0.6526228089141425, 'colsample_bytree': 0.9440950862888807, 'min_child_weight': 8, 'gamma': 0.09972590142268861}. Best is trial 63 with value: -0.6607142857142857.\n",
            "[I 2024-10-16 08:12:41,255] Trial 65 finished with value: -0.6696428571428571 and parameters: {'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.018682627900716068, 'subsample': 0.7320923097431464, 'colsample_bytree': 0.8738846927260885, 'min_child_weight': 8, 'gamma': 0.4269126153605913}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:41,444] Trial 66 finished with value: -0.6607142857142857 and parameters: {'n_estimators': 133, 'max_depth': 4, 'learning_rate': 0.020660216851845433, 'subsample': 0.7358064459101489, 'colsample_bytree': 0.9404799898612631, 'min_child_weight': 8, 'gamma': 0.07864568040146204}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:41,834] Trial 67 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 126, 'max_depth': 4, 'learning_rate': 0.0733554785518681, 'subsample': 0.7265638138092149, 'colsample_bytree': 0.9420899796775977, 'min_child_weight': 8, 'gamma': 0.11138096650229143}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:42,082] Trial 68 finished with value: -0.5714285714285714 and parameters: {'n_estimators': 133, 'max_depth': 4, 'learning_rate': 0.17546820250934936, 'subsample': 0.8400440104357347, 'colsample_bytree': 0.9088116953527072, 'min_child_weight': 8, 'gamma': 0.1466539293053527}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:42,506] Trial 69 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.04522173140811289, 'subsample': 0.7655254981251839, 'colsample_bytree': 0.8431949395883263, 'min_child_weight': 7, 'gamma': 0.16869916022320086}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:42,724] Trial 70 finished with value: -0.65625 and parameters: {'n_estimators': 131, 'max_depth': 3, 'learning_rate': 0.0451395743252548, 'subsample': 0.7838827458785912, 'colsample_bytree': 0.8671937397684016, 'min_child_weight': 7, 'gamma': 0.4842228953622357}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:43,277] Trial 71 finished with value: -0.6160714285714286 and parameters: {'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.11239169760621606, 'subsample': 0.7748748329204498, 'colsample_bytree': 0.8404845500350872, 'min_child_weight': 7, 'gamma': 0.03708290648135403}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:43,432] Trial 72 finished with value: -0.6696428571428571 and parameters: {'n_estimators': 132, 'max_depth': 3, 'learning_rate': 0.04202463938485451, 'subsample': 0.7678871850306304, 'colsample_bytree': 0.8667514886002949, 'min_child_weight': 7, 'gamma': 0.2383573710619844}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:43,842] Trial 73 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 138, 'max_depth': 3, 'learning_rate': 0.04125055165663501, 'subsample': 0.7391273718812266, 'colsample_bytree': 0.8665331503887715, 'min_child_weight': 6, 'gamma': 0.238958811679518}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:44,199] Trial 74 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 140, 'max_depth': 3, 'learning_rate': 0.045247896042004146, 'subsample': 0.7628416038094091, 'colsample_bytree': 0.8662896365116055, 'min_child_weight': 6, 'gamma': 0.22758155381177397}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:44,516] Trial 75 finished with value: -0.6428571428571429 and parameters: {'n_estimators': 141, 'max_depth': 3, 'learning_rate': 0.04436661983664824, 'subsample': 0.7397023377528209, 'colsample_bytree': 0.866065283671222, 'min_child_weight': 6, 'gamma': 0.22792789687564916}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:44,814] Trial 76 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 145, 'max_depth': 3, 'learning_rate': 0.09263701655633153, 'subsample': 0.7371757794915528, 'colsample_bytree': 0.8084778417693639, 'min_child_weight': 7, 'gamma': 0.17506501456379825}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:45,187] Trial 77 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 131, 'max_depth': 3, 'learning_rate': 0.06671535929210336, 'subsample': 0.7943952573396726, 'colsample_bytree': 0.7619927316074037, 'min_child_weight': 7, 'gamma': 0.1614551812161138}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:45,471] Trial 78 finished with value: -0.6383928571428571 and parameters: {'n_estimators': 131, 'max_depth': 3, 'learning_rate': 0.06107841322846881, 'subsample': 0.7961668519686308, 'colsample_bytree': 0.8408120755684771, 'min_child_weight': 6, 'gamma': 0.255868507175614}. Best is trial 65 with value: -0.6696428571428571.\n",
            "[I 2024-10-16 08:12:45,821] Trial 79 finished with value: -0.6741071428571429 and parameters: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.0350301845605717, 'subsample': 0.8122597940758953, 'colsample_bytree': 0.8463962105548805, 'min_child_weight': 6, 'gamma': 0.27131037264162033}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:46,274] Trial 80 finished with value: -0.6428571428571429 and parameters: {'n_estimators': 136, 'max_depth': 4, 'learning_rate': 0.03251144145100475, 'subsample': 0.818146931713189, 'colsample_bytree': 0.8183925537841861, 'min_child_weight': 7, 'gamma': 0.28913645379126013}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:46,578] Trial 81 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 147, 'max_depth': 4, 'learning_rate': 0.03279433736119895, 'subsample': 0.8291927008078667, 'colsample_bytree': 0.7800545514436221, 'min_child_weight': 7, 'gamma': 0.280729572959711}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:46,905] Trial 82 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 147, 'max_depth': 4, 'learning_rate': 0.05273980668540547, 'subsample': 0.7745846828996311, 'colsample_bytree': 0.7787262794696077, 'min_child_weight': 6, 'gamma': 0.23994401141724875}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:46,992] Trial 83 finished with value: -0.65625 and parameters: {'n_estimators': 138, 'max_depth': 3, 'learning_rate': 0.053383294331991585, 'subsample': 0.8710073211651809, 'colsample_bytree': 0.8921825744774222, 'min_child_weight': 6, 'gamma': 0.19031268514466518}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:47,338] Trial 84 finished with value: -0.6607142857142857 and parameters: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.018275189953157876, 'subsample': 0.7132980521149007, 'colsample_bytree': 0.8918452681837087, 'min_child_weight': 6, 'gamma': 0.18815902161967815}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:47,381] Trial 85 finished with value: -0.6607142857142857 and parameters: {'n_estimators': 131, 'max_depth': 3, 'learning_rate': 0.07375188232895344, 'subsample': 0.9050058352045418, 'colsample_bytree': 0.8782849229670361, 'min_child_weight': 5, 'gamma': 0.1967601828009845}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:47,777] Trial 86 finished with value: -0.6026785714285714 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.1495723418142226, 'subsample': 0.8689414779261257, 'colsample_bytree': 0.879040417252763, 'min_child_weight': 5, 'gamma': 0.19127500260726593}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:47,799] Trial 87 finished with value: -0.6696428571428571 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.016883958057339096, 'subsample': 0.8816760966451684, 'colsample_bytree': 0.8925448235312564, 'min_child_weight': 5, 'gamma': 0.18705639570785174}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,149] Trial 88 finished with value: -0.65625 and parameters: {'n_estimators': 136, 'max_depth': 3, 'learning_rate': 0.07158780257197467, 'subsample': 0.8874071272527121, 'colsample_bytree': 0.8966221828106297, 'min_child_weight': 4, 'gamma': 0.13645018830157477}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,191] Trial 89 finished with value: -0.6294642857142857 and parameters: {'n_estimators': 136, 'max_depth': 3, 'learning_rate': 0.017797273318788245, 'subsample': 0.8975547801215442, 'colsample_bytree': 0.9227896906616739, 'min_child_weight': 4, 'gamma': 0.21722250321104683}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,519] Trial 91 finished with value: -0.6651785714285714 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.03618033037271815, 'subsample': 0.7142932640739428, 'colsample_bytree': 0.9308695107380122, 'min_child_weight': 6, 'gamma': 0.06628969214741008}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,546] Trial 90 finished with value: -0.65625 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.01864617953653669, 'subsample': 0.7117989321050936, 'colsample_bytree': 0.8762820994191775, 'min_child_weight': 5, 'gamma': 0.2126299227434864}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,924] Trial 93 finished with value: -0.6383928571428571 and parameters: {'n_estimators': 129, 'max_depth': 3, 'learning_rate': 0.03748195533387515, 'subsample': 0.7852020354755627, 'colsample_bytree': 0.8547143314745814, 'min_child_weight': 5, 'gamma': 0.06748870563572067}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:48,945] Trial 92 finished with value: -0.6517857142857143 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.03666444430670394, 'subsample': 0.9370435865533113, 'colsample_bytree': 0.930802658001869, 'min_child_weight': 5, 'gamma': 0.06081271333997745}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:49,288] Trial 94 finished with value: -0.6473214285714286 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.031013500707240935, 'subsample': 0.6795212527020327, 'colsample_bytree': 0.9304234284513608, 'min_child_weight': 5, 'gamma': 0.058037960361405294}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:49,387] Trial 95 finished with value: -0.65625 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.024410838283820385, 'subsample': 0.6808922813717375, 'colsample_bytree': 0.8916223566307145, 'min_child_weight': 6, 'gamma': 0.08490452058554906}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:49,707] Trial 96 finished with value: -0.6651785714285714 and parameters: {'n_estimators': 142, 'max_depth': 3, 'learning_rate': 0.024068043853507495, 'subsample': 0.7545203160932601, 'colsample_bytree': 0.891270862015398, 'min_child_weight': 6, 'gamma': 0.08891132798395704}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:49,872] Trial 97 finished with value: -0.6741071428571429 and parameters: {'n_estimators': 131, 'max_depth': 4, 'learning_rate': 0.020727575312678905, 'subsample': 0.7152024152061677, 'colsample_bytree': 0.9143857367013676, 'min_child_weight': 6, 'gamma': 0.139599745458974}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:50,200] Trial 98 finished with value: -0.6741071428571429 and parameters: {'n_estimators': 140, 'max_depth': 4, 'learning_rate': 0.016443928074407234, 'subsample': 0.7151488890868168, 'colsample_bytree': 0.9000180672134764, 'min_child_weight': 6, 'gamma': 0.12328370719301836}. Best is trial 79 with value: -0.6741071428571429.\n",
            "[I 2024-10-16 08:12:50,302] Trial 99 finished with value: -0.6696428571428571 and parameters: {'n_estimators': 140, 'max_depth': 4, 'learning_rate': 0.015420341073830465, 'subsample': 0.7533028813747938, 'colsample_bytree': 0.9172028823844741, 'min_child_weight': 6, 'gamma': 0.11262957902585743}. Best is trial 79 with value: -0.6741071428571429.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best parameters found: {study.best_params}\")\n",
        "print(f\"Best score found: {study.best_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_n9alHrY1dV",
        "outputId": "145fc67a-f858-41e1-e4ab-f16b1b128367"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.0350301845605717, 'subsample': 0.8122597940758953, 'colsample_bytree': 0.8463962105548805, 'min_child_weight': 6, 'gamma': 0.27131037264162033}\n",
            "Best score found: -0.6741071428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### GBMClassifier"
      ],
      "metadata": {
        "id": "8uQu5miBYDzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "X_cv = X_cv[X_train.columns]\n",
        "\n",
        "#create an instance of the gradient boosting classifier\n",
        "gbm = GradientBoostingClassifier(subsample=0.7, n_estimators=900,\n",
        "                                 min_samples_leaf= 2,\n",
        "                                 min_impurity_decrease=0.05,\n",
        "                                 max_features='sqrt', max_depth=7,\n",
        "                                 loss='exponential',\n",
        "                                 learning_rate=0.01,\n",
        "                                 criterion='friedman_mse')\n",
        "\n",
        "#fit the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "#make prediction on the test set\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "#calculate accuracy, precision_recall, f1\n",
        "accuracy = accuracy_score(y_test, y_pred_gbm)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHDw9T-np2pN",
        "outputId": "8425fd67-3582-42f2-e9a3-fe3bbcfbdf3f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.59375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optuna to tune GBM\n",
        "def obj_fun_gbm(trial):\n",
        "    # Suggest hyperparameters\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error']),\n",
        "        'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.1),\n",
        "    }\n",
        "\n",
        "    #Define and fit the GBM model\n",
        "    model = GradientBoostingClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    return -accuracy  # Negative accuracy to minimize"
      ],
      "metadata": {
        "id": "Kj-N1ei-iZW0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(obj_fun_gbm, n_trials=100)\n",
        "\n",
        "# Get the best trial\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print(f\"Best trial: {best_trial.params}\")\n",
        "print(f\"Best accuracy: {best_trial.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0M8z8jzjrCK",
        "outputId": "5e3dd82a-8beb-48bf-9525-2420f18ab398"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-16 18:26:28,117] A new study created in memory with name: no-name-d0531218-aeb8-4d3c-9b11-3d6a8ec36a5e\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:29,849] Trial 0 finished with value: -0.5 and parameters: {'n_estimators': 961, 'learning_rate': 0.018075251985629544, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 20, 'subsample': 0.839654428276609, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06159344093649477}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:30,327] Trial 1 finished with value: -0.5 and parameters: {'n_estimators': 246, 'learning_rate': 0.023709188174451834, 'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 6, 'subsample': 0.6982969407307795, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.047354546181613666}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:31,264] Trial 2 finished with value: -0.5 and parameters: {'n_estimators': 486, 'learning_rate': 0.014188861611321121, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 15, 'subsample': 0.6027772838730795, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.012730690774210152}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:32,121] Trial 3 finished with value: -0.5 and parameters: {'n_estimators': 183, 'learning_rate': 0.019748830630716478, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 12, 'subsample': 0.8296535910798666, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.016259811494394916}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:41,938] Trial 4 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 907, 'learning_rate': 0.0287831174591994, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.9198493906023484, 'max_features': None, 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.06440016308765828}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:42,902] Trial 5 finished with value: -0.5 and parameters: {'n_estimators': 651, 'learning_rate': 0.10620257742153275, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 13, 'subsample': 0.9018477097914193, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.008456057282940443}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:44,674] Trial 6 finished with value: -0.6294642857142857 and parameters: {'n_estimators': 720, 'learning_rate': 0.15473954103641666, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 7, 'subsample': 0.9774422748706033, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.024299003554845724}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:45,407] Trial 7 finished with value: -0.6651785714285714 and parameters: {'n_estimators': 194, 'learning_rate': 0.028891191097185964, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 13, 'subsample': 0.8798715334223748, 'max_features': 'sqrt', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.036557142154629386}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:45,703] Trial 8 finished with value: -0.5 and parameters: {'n_estimators': 150, 'learning_rate': 0.05448501704868271, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 8, 'subsample': 0.9812046619813921, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.01438784708304297}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:53,715] Trial 9 finished with value: -0.59375 and parameters: {'n_estimators': 618, 'learning_rate': 0.01603292723134093, 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 20, 'subsample': 0.7465714021187686, 'max_features': None, 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.01566792887579892}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:55,106] Trial 10 finished with value: -0.5 and parameters: {'n_estimators': 993, 'learning_rate': 0.05610996003013763, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 18, 'subsample': 0.5270338142522688, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.09108661242872651}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:55,714] Trial 11 finished with value: -0.5 and parameters: {'n_estimators': 393, 'learning_rate': 0.010460646265073146, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 2, 'subsample': 0.7115654957921036, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0637040189691781}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:56,265] Trial 12 finished with value: -0.5 and parameters: {'n_estimators': 337, 'learning_rate': 0.03675557597029892, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6578451049809717, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05465540314584205}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:57,481] Trial 13 finished with value: -0.5 and parameters: {'n_estimators': 803, 'learning_rate': 0.29164839426391687, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8089111954410447, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.08324022382364767}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:58,007] Trial 14 finished with value: -0.5 and parameters: {'n_estimators': 324, 'learning_rate': 0.021380991466588003, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.7981976338702309, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.03907322868745303}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:26:58,839] Trial 15 finished with value: -0.5 and parameters: {'n_estimators': 521, 'learning_rate': 0.010230789738602504, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 16, 'subsample': 0.6575762440351817, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.07816163675316108}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:00,468] Trial 16 finished with value: -0.5 and parameters: {'n_estimators': 831, 'learning_rate': 0.04804376113294941, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.7086956894907016, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.04502990363333648}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:01,022] Trial 17 finished with value: -0.5 and parameters: {'n_estimators': 264, 'learning_rate': 0.07227174455608582, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 20, 'subsample': 0.5314548834141233, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06750845274012592}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:04,160] Trial 18 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 444, 'learning_rate': 0.027502008072684103, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.6080008622816375, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.0557775597810445}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:06,079] Trial 19 finished with value: -0.5 and parameters: {'n_estimators': 594, 'learning_rate': 0.014484455892664562, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 5, 'subsample': 0.8537954035170492, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.02862201766172068}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:07,162] Trial 20 finished with value: -0.5 and parameters: {'n_estimators': 717, 'learning_rate': 0.03761254996964413, 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 16, 'subsample': 0.7799702509927804, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.07580932925634219}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:07,949] Trial 21 finished with value: -0.5848214285714286 and parameters: {'n_estimators': 512, 'learning_rate': 0.014041822338217297, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 15, 'subsample': 0.6110367485218493, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0029711263881175565}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:08,564] Trial 22 finished with value: -0.5 and parameters: {'n_estimators': 405, 'learning_rate': 0.020247616441966942, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 18, 'subsample': 0.5765283003028852, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.048225928193698045}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:08,981] Trial 23 finished with value: -0.5 and parameters: {'n_estimators': 257, 'learning_rate': 0.01610299600171981, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 18, 'subsample': 0.6719976718169804, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.03265334208992116}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:09,187] Trial 24 finished with value: -0.5 and parameters: {'n_estimators': 101, 'learning_rate': 0.023752908135902157, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 15, 'subsample': 0.7441021882029859, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.09712160179514931}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:09,932] Trial 25 finished with value: -0.5 and parameters: {'n_estimators': 523, 'learning_rate': 0.010916544334249673, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 12, 'subsample': 0.5913678195964398, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05664986384714971}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:13,452] Trial 26 finished with value: -0.5625 and parameters: {'n_estimators': 994, 'learning_rate': 0.03559272268019304, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 19, 'subsample': 0.6947174929422556, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.04174172092307537}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:14,344] Trial 27 finished with value: -0.5 and parameters: {'n_estimators': 473, 'learning_rate': 0.012871544642964637, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 16, 'subsample': 0.5595281989258102, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.022860596104106325}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:16,955] Trial 28 finished with value: -0.5 and parameters: {'n_estimators': 706, 'learning_rate': 0.01726875734367929, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6384165847947199, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.07177681162203066}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:19,168] Trial 29 finished with value: -0.6339285714285714 and parameters: {'n_estimators': 805, 'learning_rate': 0.019427936366952572, 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 12, 'subsample': 0.8285840752086688, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.00043820325304092834}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:19,971] Trial 30 finished with value: -0.5 and parameters: {'n_estimators': 250, 'learning_rate': 0.025318191610784656, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 14, 'subsample': 0.7723628678821249, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.05893386173115712}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:20,687] Trial 31 finished with value: -0.5 and parameters: {'n_estimators': 194, 'learning_rate': 0.012694564902012772, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 11, 'subsample': 0.9289241938068312, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.016168400132220526}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:21,833] Trial 32 finished with value: -0.5 and parameters: {'n_estimators': 341, 'learning_rate': 0.030217337980818434, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.8449267041224571, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.021550328483695695}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:22,930] Trial 33 finished with value: -0.6696428571428571 and parameters: {'n_estimators': 100, 'learning_rate': 0.01933153156353057, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 11, 'subsample': 0.9286877111641993, 'max_features': None, 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.005547529374263338}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:25,876] Trial 34 finished with value: -0.5 and parameters: {'n_estimators': 890, 'learning_rate': 0.023498393597128145, 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 9, 'subsample': 0.8882760263494068, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.010884769626844391}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:26,622] Trial 35 finished with value: -0.59375 and parameters: {'n_estimators': 169, 'learning_rate': 0.1291082225950152, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 13, 'subsample': 0.8632999072832085, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.02912739148841404}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:28,032] Trial 36 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 577, 'learning_rate': 0.030760408961389422, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 6, 'subsample': 0.5040987517105923, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.010798013263755924}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:28,582] Trial 37 finished with value: -0.5 and parameters: {'n_estimators': 256, 'learning_rate': 0.09346788190789311, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 17, 'subsample': 0.731780827060271, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0629874523618483}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:31,666] Trial 38 finished with value: -0.59375 and parameters: {'n_estimators': 665, 'learning_rate': 0.04270757135966258, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 14, 'subsample': 0.9534675330448839, 'max_features': 'sqrt', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.033595930751362975}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:32,976] Trial 39 finished with value: -0.5 and parameters: {'n_estimators': 308, 'learning_rate': 0.016469881346963876, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.7669839898828964, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.049386458534952646}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:33,344] Trial 40 finished with value: -0.5 and parameters: {'n_estimators': 201, 'learning_rate': 0.012092320595413165, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.8242154635525851, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.01973278051877564}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:34,722] Trial 41 finished with value: -0.5 and parameters: {'n_estimators': 921, 'learning_rate': 0.2056669972839658, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 13, 'subsample': 0.8934745058950311, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.00797216922467679}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:35,330] Trial 42 finished with value: -0.5 and parameters: {'n_estimators': 372, 'learning_rate': 0.06396005508802857, 'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 13, 'subsample': 0.9016738601726638, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.01668582847159575}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:36,356] Trial 43 finished with value: -0.5 and parameters: {'n_estimators': 660, 'learning_rate': 0.10760766770165016, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 9, 'subsample': 0.86511576775454, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.01185714184685363}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:37,494] Trial 44 finished with value: -0.5 and parameters: {'n_estimators': 758, 'learning_rate': 0.1928645908544187, 'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 19, 'subsample': 0.7967471800252319, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.02674865302628246}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:38,225] Trial 45 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 451, 'learning_rate': 0.08148155762775194, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 14, 'subsample': 0.9991394288725903, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.005118743651582642}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:39,628] Trial 46 finished with value: -0.5 and parameters: {'n_estimators': 936, 'learning_rate': 0.018589825746634127, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 15, 'subsample': 0.835107695368735, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.03741452943558332}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:41,069] Trial 47 finished with value: -0.5803571428571429 and parameters: {'n_estimators': 754, 'learning_rate': 0.16123221641823995, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9, 'subsample': 0.9433799261463601, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.084056312327681}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:42,369] Trial 48 finished with value: -0.5 and parameters: {'n_estimators': 859, 'learning_rate': 0.014192398818497078, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.813888513324347, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.018678495455739}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:43,538] Trial 49 finished with value: -0.5 and parameters: {'n_estimators': 635, 'learning_rate': 0.05355650092272898, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 17, 'subsample': 0.9100235461581561, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06881325512560973}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:44,141] Trial 50 finished with value: -0.5 and parameters: {'n_estimators': 285, 'learning_rate': 0.032526276602841735, 'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 20, 'subsample': 0.6313811291368918, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05244947424880279}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:44,537] Trial 51 finished with value: -0.5 and parameters: {'n_estimators': 142, 'learning_rate': 0.04367431329708078, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 6, 'subsample': 0.9654230674321906, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.012989690619126552}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:45,031] Trial 52 finished with value: -0.5 and parameters: {'n_estimators': 212, 'learning_rate': 0.023317566640063712, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 7, 'subsample': 0.876740793839341, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.025092639984963826}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:45,564] Trial 53 finished with value: -0.6383928571428571 and parameters: {'n_estimators': 148, 'learning_rate': 0.027518919374779627, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10, 'subsample': 0.9839338758789851, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.000879685760924731}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:46,121] Trial 54 finished with value: -0.5 and parameters: {'n_estimators': 227, 'learning_rate': 0.06863698458971013, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.6952675943635596, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.045320186741516735}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:47,055] Trial 55 finished with value: -0.5669642857142857 and parameters: {'n_estimators': 412, 'learning_rate': 0.015461619732499475, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 11, 'subsample': 0.799686073530919, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.007801547301125205}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:47,434] Trial 56 finished with value: -0.5 and parameters: {'n_estimators': 139, 'learning_rate': 0.2554642196677234, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7378805890726161, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06093488045201105}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:48,877] Trial 57 finished with value: -0.5 and parameters: {'n_estimators': 559, 'learning_rate': 0.01014921997987297, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.5477946845320364, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.030972736235063542}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:50,616] Trial 58 finished with value: -0.6205357142857143 and parameters: {'n_estimators': 365, 'learning_rate': 0.02124641997706513, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 17, 'subsample': 0.919345600393689, 'max_features': 'sqrt', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.01325144169491691}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:51,140] Trial 59 finished with value: -0.5 and parameters: {'n_estimators': 302, 'learning_rate': 0.1345854491382977, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 12, 'subsample': 0.7836991488296503, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.04034224472398169}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:52,592] Trial 60 finished with value: -0.5 and parameters: {'n_estimators': 961, 'learning_rate': 0.0578754253953524, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7565023147084108, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.022790503084651657}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:53,953] Trial 61 finished with value: -0.5 and parameters: {'n_estimators': 965, 'learning_rate': 0.09027668634543763, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 19, 'subsample': 0.5011759884079828, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.09709222840934979}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:55,245] Trial 62 finished with value: -0.5 and parameters: {'n_estimators': 893, 'learning_rate': 0.01782566569920434, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 18, 'subsample': 0.5274522458225138, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0825790587179621}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:56,682] Trial 63 finished with value: -0.5 and parameters: {'n_estimators': 991, 'learning_rate': 0.03706834209354048, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 20, 'subsample': 0.5931897693133346, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0888877733062041}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:27:58,083] Trial 64 finished with value: -0.5 and parameters: {'n_estimators': 855, 'learning_rate': 0.048995878018409184, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 16, 'subsample': 0.6195038348931171, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.07664625481892384}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:00,038] Trial 65 finished with value: -0.5 and parameters: {'n_estimators': 508, 'learning_rate': 0.011659126397766614, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 14, 'subsample': 0.6688623153684427, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.09439478384726693}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:00,470] Trial 66 finished with value: -0.5 and parameters: {'n_estimators': 157, 'learning_rate': 0.10498094490546982, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 19, 'subsample': 0.7154729226687576, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06723901370245663}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:02,101] Trial 67 finished with value: -0.5 and parameters: {'n_estimators': 799, 'learning_rate': 0.014002468441239105, 'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.5799735705596182, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.015188928439768155}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:07,577] Trial 68 finished with value: -0.6026785714285714 and parameters: {'n_estimators': 485, 'learning_rate': 0.021782245894858547, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 15, 'subsample': 0.5210484781622498, 'max_features': None, 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.07243195707524608}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:07,898] Trial 69 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 183, 'learning_rate': 0.015820083494993403, 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 4, 'subsample': 0.5510961673904651, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.008096098345698329}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:08,146] Trial 70 finished with value: -0.5 and parameters: {'n_estimators': 121, 'learning_rate': 0.026560631923874194, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 18, 'subsample': 0.943202050060554, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.04415612533695601}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:08,791] Trial 71 finished with value: -0.5 and parameters: {'n_estimators': 409, 'learning_rate': 0.012663871428246556, 'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 1, 'subsample': 0.7212322317794426, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05867480311704693}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:09,728] Trial 72 finished with value: -0.5 and parameters: {'n_estimators': 605, 'learning_rate': 0.010737645337303247, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 2, 'subsample': 0.6921251598014618, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.052440136565605665}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:10,125] Trial 73 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 223, 'learning_rate': 0.013576784135682519, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 10, 'subsample': 0.6394702749352725, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0049720890462910585}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:10,848] Trial 74 finished with value: -0.5 and parameters: {'n_estimators': 439, 'learning_rate': 0.07481423993081637, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 2, 'subsample': 0.8453750632949983, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06475908700392609}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:12,440] Trial 75 finished with value: -0.5 and parameters: {'n_estimators': 532, 'learning_rate': 0.011639339369787794, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 11, 'subsample': 0.677575559918939, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.08152357293477729}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:13,251] Trial 76 finished with value: -0.5 and parameters: {'n_estimators': 368, 'learning_rate': 0.015078954191630543, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 3, 'subsample': 0.6558532553224521, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0889555967112085}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:15,299] Trial 77 finished with value: -0.5 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04159311991094047, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.8848735049745058, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.01995427175209276}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:17,224] Trial 78 finished with value: -0.6473214285714286 and parameters: {'n_estimators': 277, 'learning_rate': 0.016838655209495873, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 12, 'subsample': 0.9789948906770842, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.07295821697920404}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:18,321] Trial 79 finished with value: -0.5 and parameters: {'n_estimators': 339, 'learning_rate': 0.019625540291492036, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 13, 'subsample': 0.8147597017606351, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.01773976508026226}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:18,652] Trial 80 finished with value: -0.5 and parameters: {'n_estimators': 181, 'learning_rate': 0.02485183867004831, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8598764608498377, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.035916550101218414}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:19,084] Trial 81 finished with value: -0.5 and parameters: {'n_estimators': 246, 'learning_rate': 0.033828436074409544, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.704016709766458, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.054165607668811094}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:19,612] Trial 82 finished with value: -0.5 and parameters: {'n_estimators': 318, 'learning_rate': 0.05374118410347224, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 11, 'subsample': 0.6585565259930128, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06360122013445063}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:20,360] Trial 83 finished with value: -0.5 and parameters: {'n_estimators': 470, 'learning_rate': 0.058605645973700195, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 20, 'subsample': 0.726312741561685, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05609518369301072}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:21,004] Trial 84 finished with value: -0.5 and parameters: {'n_estimators': 393, 'learning_rate': 0.02178314512329258, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9, 'subsample': 0.7476559662595387, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05983970622564805}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:21,581] Trial 85 finished with value: -0.5 and parameters: {'n_estimators': 346, 'learning_rate': 0.04012391824045528, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.6824540553744776, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.04632934653944735}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:22,264] Trial 86 finished with value: -0.5 and parameters: {'n_estimators': 434, 'learning_rate': 0.04769996599053679, 'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 7, 'subsample': 0.6068639223393648, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.05055992463836887}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:22,646] Trial 87 finished with value: -0.5 and parameters: {'n_estimators': 231, 'learning_rate': 0.018389700422480636, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.5693853155034946, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.010363744959172673}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:23,135] Trial 88 finished with value: -0.5 and parameters: {'n_estimators': 290, 'learning_rate': 0.028139813896976378, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.6487375859093278, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.0666175661407018}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:25,804] Trial 89 finished with value: -0.5 and parameters: {'n_estimators': 941, 'learning_rate': 0.030622474571890816, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 15, 'subsample': 0.7061552532440879, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.025682940754400845}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:26,470] Trial 90 finished with value: -0.5892857142857143 and parameters: {'n_estimators': 122, 'learning_rate': 0.04578528865059722, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 17, 'subsample': 0.873846024605977, 'max_features': 'log2', 'criterion': 'friedman_mse', 'min_impurity_decrease': 0.014868377900006535}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:27,829] Trial 91 finished with value: -0.5 and parameters: {'n_estimators': 721, 'learning_rate': 0.12174860466356381, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8391376658291255, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.08753355652105524}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:29,376] Trial 92 finished with value: -0.5 and parameters: {'n_estimators': 781, 'learning_rate': 0.29398923527324466, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7957556429758197, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.09299484624926739}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:31,244] Trial 93 finished with value: -0.5 and parameters: {'n_estimators': 879, 'learning_rate': 0.06500034102157079, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.8217506307016246, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.07951846046373327}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:32,695] Trial 94 finished with value: -0.5 and parameters: {'n_estimators': 824, 'learning_rate': 0.16129001998199602, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.9998559927412312, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.07050877038879556}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:34,164] Trial 95 finished with value: -0.5 and parameters: {'n_estimators': 967, 'learning_rate': 0.18208419559961922, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12, 'subsample': 0.9069270456264357, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.09897064756657259}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:35,214] Trial 96 finished with value: -0.5758928571428571 and parameters: {'n_estimators': 658, 'learning_rate': 0.020679474087826992, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.7641406995258976, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.003318465632816077}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:36,295] Trial 97 finished with value: -0.5 and parameters: {'n_estimators': 696, 'learning_rate': 0.24278021967363916, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.8506197514969843, 'max_features': 'log2', 'criterion': 'squared_error', 'min_impurity_decrease': 0.08565964162602438}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:38,222] Trial 98 finished with value: -0.5 and parameters: {'n_estimators': 557, 'learning_rate': 0.023490480825512666, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 18, 'subsample': 0.9629464435423452, 'max_features': None, 'criterion': 'squared_error', 'min_impurity_decrease': 0.07486922646754915}. Best is trial 0 with value: -0.5.\n",
            "<ipython-input-83-f99a82a15c2f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "[I 2024-10-16 18:28:39,581] Trial 99 finished with value: -0.5 and parameters: {'n_estimators': 914, 'learning_rate': 0.08115460790662343, 'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 13, 'subsample': 0.7828028627990847, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06131611784009453}. Best is trial 0 with value: -0.5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'n_estimators': 961, 'learning_rate': 0.018075251985629544, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 20, 'subsample': 0.839654428276609, 'max_features': 'sqrt', 'criterion': 'squared_error', 'min_impurity_decrease': 0.06159344093649477}\n",
            "Best accuracy: -0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LightGBM\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_lgbm)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TadCBcvQo3tG",
        "outputId": "120d574b-3576-4922-f771-e5eece666f08"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 894, number of negative: 894\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2272\n",
            "[LightGBM] [Info] Number of data points in the train set: 1788, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Accuracy: 0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tuning LGBM with randomizedsearchCV"
      ],
      "metadata": {
        "id": "dD0ya2Q-pEMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble learning"
      ],
      "metadata": {
        "id": "_ziidvaWuqVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "estimators = [\n",
        "    ('gbm', gbm),\n",
        "    ('rf', clf)\n",
        "]\n",
        "\n",
        "stacked_model = StackingClassifier(estimators=estimators, final_estimator=LR())\n",
        "\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "predictions = stacked_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMYA_dlPuqDn",
        "outputId": "27e7051b-c234-46d5-9437-7bba6cc97f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6116071428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
        "\n",
        "rf = clf\n",
        "ada = ABC(estimator=rf, n_estimators=100, learning_rate=0.1)\n",
        "\n",
        "skf = SKF(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = CVS(ada, X_train, y_train, cv=skf)\n",
        "print(f\"Cross-Validation Accuracy: {scores.mean()}\")\n",
        "print(f\"Mean CV Accuracy: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydQ7JgrJnXFx",
        "outputId": "ede6519d-f2f0-4ff6-b746-19de9e93238f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 0.689016165125268\n",
            "Mean CV Accuracy: 0.69\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}